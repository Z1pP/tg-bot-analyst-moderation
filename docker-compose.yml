version: '3.8'

# 1. –®–∞–±–ª–æ–Ω –æ–±—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ (—Å–±–æ—Ä–∫–∞, —Ä–µ—Å—Ç–∞—Ä—Ç, —Å–µ—Ç—å, –ª–æ–≥–∏)
x-common-setup: &common-setup
  build: .
  restart: unless-stopped
  env_file: .env
  networks:
    - botnet
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  volumes:
    - ./logs:/app/logs
    - .:/app

# 2. –®–∞–±–ª–æ–Ω –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î –∏ Redis –≤–Ω—É—Ç—Ä–∏ —Å–µ—Ç–∏ Docker
x-db-env: &db-env
  # –≠—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç —Ç–æ, —á—Ç–æ –≤ .env, —Ç–∞–∫ –∫–∞–∫ –≤–Ω—É—Ç—Ä–∏ Docker —Ö–æ—Å—Ç—ã –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è 'db' –∏ 'redis'
  DEV_DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
  DEV_DB_URL_FOR_ALEMBIC: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
  PROD_DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
  PROD_DB_URL_FOR_ALEMBIC: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
  REDIS_URL: redis://${REDIS_HOST:-redis}:${REDIS_PORT:-6379}/${REDIS_DB:-0}
  PYTHONPATH: /app/src

services:
  bot:
    <<: *common-setup
    ports:
      - "8000:8000"
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
      tunnel: { condition: service_started }
    environment:
      <<: *db-env
      SERVICE_NAME: bot
      USE_WEBHOOK: "True"
    command: >
      bash -c "
        echo '‚è≥ Waiting for Cloudflare Tunnel...';
        until curl -s http://tunnel:4040/metrics | grep -q 'cloudflared_tunnel_user_hostnames_counts'; do
          sleep 2;
        done;
        PUBLIC_URL=\$$(curl -s http://tunnel:4040/metrics | grep -Eo 'https://[a-z0-9-]+\.trycloudflare\.com' | head -1);
        echo 'üåê Public URL: ' \$$PUBLIC_URL;
        python src/main.py --webhook-url \$$PUBLIC_URL
      "

  db:
    image: postgres:14
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      TZ: ${TIMEZONE:-Europe/Moscow}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "127.0.0.1:${POSTGRES_EXTERNAL_PORT:-5434}:5432"
    networks:
      - botnet

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - botnet

  tunnel:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel --url http://bot:8000 --metrics 0.0.0.0:4040
    networks:
      - botnet

  scheduler:
    <<: *common-setup
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
    environment:
      <<: *db-env
      SERVICE_NAME: scheduler
    command: python src/taskiq_scheduler_entrypoint.py

  analytics_scheduler:
    <<: *common-setup
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
    environment:
      <<: *db-env
      SERVICE_NAME: analytics_scheduler
    command: python src/analytics_scheduler_entrypoint.py

  worker:
    <<: *common-setup
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
    environment:
      <<: *db-env
      SERVICE_NAME: worker
    command: taskiq worker scheduler.taskiq:broker tasks.report_tasks tasks.analytics_tasks

networks:
  botnet:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
